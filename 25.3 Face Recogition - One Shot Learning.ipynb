{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "haar_xml = pkg_resources.resource_filename(\n",
    "    'cv2', 'data/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.2.0 in ./opt/anaconda3/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.20.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (0.36.2)\n",
      "Requirement already satisfied: astunparse==1.6.3 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (3.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (2.2.2)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.4.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (0.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (3.3.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.1.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.32.0)\n",
      "Requirement already satisfied: gast==0.3.3 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (0.3.3)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow==2.2.0) (46.0.0.post20200309)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.22.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.21.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in ./opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.5.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./opt/anaconda3/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv2.CascadeClassifier(haar_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected image names\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "\n",
    "\n",
    "face_detector = classifier\n",
    "\n",
    "\n",
    "mypath = \"/Users/lav/Desktop/25. Face Recognition/people\"\n",
    "image_file_names = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(\"Collected image names\")\n",
    "\n",
    "for image_name in image_file_names:\n",
    "    if image_name=='.DS_Store':\n",
    "        continue\n",
    "    person_image = cv2.imread(mypath+'/'+image_name)\n",
    "    face_info = face_detector.detectMultiScale(person_image)\n",
    "    for (x,y,w,h) in face_info:\n",
    "        face = person_image[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(face, (128, 128), interpolation = cv2.INTER_CUBIC)\n",
    "    path = '/Users/lav/Desktop/25. Face Recognition/group_of_faces/'+ image_name \n",
    "    cv2.imwrite(path, roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Loads image from path and resizes it\"\"\"\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def loadVggFaceModel():\n",
    "    \"\"\"Loads the VGGFace model defined in the function\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    #you can download pretrained weights from https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "    from keras.models import model_from_json\n",
    "    model.load_weights('/Users/lav/Downloads/vgg_face_weights.h5')\n",
    "\n",
    "    vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n",
    "\n",
    "    return vgg_face_descriptor\n",
    "\n",
    "model = loadVggFaceModel()\n",
    "print(\"Model Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test model using your Webcam\n",
    "This code looks up the faces you extracted in the \"group_of_faces\" folder and uses the similarity (Cosine Similarity) to detect which faces is most similar to the one being extracted with your webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'no_mask_lav.jpg', 'Mask.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_pictures='/Users/lav/Desktop/25. Face Recognition/group_of_faces'\n",
    "all_people_faces = dict()\n",
    "listdir(people_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face representations retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "people_pictures = '/Users/lav/Desktop/25. Face Recognition/group_of_faces'\n",
    "\n",
    "all_people_faces = dict()\n",
    "\n",
    "for file in listdir(people_pictures):\n",
    "    if file == '.DS_Store':\n",
    "        continue\n",
    "    person_face, extension = file.split(\".\")\n",
    "    person_face=str(person_face)\n",
    "    all_people_faces[person_face] = model.predict(preprocess_image(f'/Users/lav/Desktop/25. Face Recognition/group_of_faces/{person_face}.jpg'))[0,:]\n",
    "\n",
    "print(\"Face representations retrieved successfully\")\n",
    "\n",
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "#Open Webcam\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    faces = classifier.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        if w > 100: #Adjust accordingly if your webcam resoluation is higher\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) #draw rectangle to main image\n",
    "            detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "            detected_face = cv2.resize(detected_face, (224, 224)) #resize to 224x224\n",
    "\n",
    "            img_pixels = image.img_to_array(detected_face)\n",
    "            img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "            img_pixels /= 255\n",
    "\n",
    "            captured_representation = model.predict(img_pixels)[0,:]\n",
    "\n",
    "            found = 0\n",
    "            for i in all_people_faces:\n",
    "                person_name = i\n",
    "                representation = all_people_faces[i]\n",
    "\n",
    "                similarity = findCosineSimilarity(representation, captured_representation)\n",
    "                if(similarity < 0.30):\n",
    "                    cv2.putText(img, person_name[0:7], (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    found = 1\n",
    "                    break\n",
    "\n",
    "            #connect face and text\n",
    "            cv2.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "            cv2.line(img,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "            if(found == 0): #if found image is not in our people database\n",
    "                cv2.putText(img, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
